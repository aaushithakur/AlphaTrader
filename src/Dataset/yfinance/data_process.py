# -*- coding: utf-8 -*-
"""Stock bot input.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sqCSNeSDZJrtPfS8RVy155MdV5Nt0F1r
"""
# !pip install fastparquet
from pandas_datareader import data as pdr
import yfinance as yf
import pandas as pd
import talib as ta
import yfinance as yf
from copy import deepcopy
import os, sys
base_path = os.getcwd() + '/src'
sys.path.append(base_path)
import Shared.configs.config_main as main_config

stock_df = {}
feature_df = {}

def fetch_stock_data(ticker):
  global stock_df
#   XXX: Caching has to be date wise on prod

  if os.environ.get('ENV') == 'Simulation':
    if stock_df.get(ticker, None) is not None:
        return stock_df[ticker]
  tick = yf.Ticker(ticker)
  df = tick.history(start=main_config.STOCK_DATA_START_PRED, end=main_config.STOCK_DATA_END_PRED)
  df['Adj Close'] = deepcopy(df['Close'])
  df.drop(columns=['Adj Close'])
  df = df.rename(columns = {
    'Open': 'AdjOpen',
    'High': 'AdjHigh',
    'Low': 'AdjLow',
    'Close': 'AdjClose',
    'Volume': 'AdjVolume',
    })
  df = df.reset_index()
  df['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')
  
  df = df[['Date', 'AdjOpen', 'AdjHigh', 'AdjLow', 'AdjClose', 'AdjVolume']]
  #Date	      AdjLow	           AdjOpen	    AdjVolume	 AdjHigh	            AdjClose	         Adjusted Close
  #19-11-2019	66.34750366210940	66.9749984741211	76167200	67.0	            66.57250213623050	   65.41852569580080
  #20-11-2019	65.0999984741211	66.38500213623050	106234400	66.5199966430664	65.79750061035160	   64.65695190429690
  stock_df[ticker] = df
  #   print(stock_df.loc[stock_df['Date'] == '22-03-2019'])
  return df

def fetch_stock_data_RL(ticker, start_date, end_date):
  global stock_df
#   XXX: Caching has to be date wise on prod

  if os.environ.get('ENV') == 'Simulation':
    if stock_df.get(ticker, None) is not None:
        return stock_df[ticker]
  tick = yf.Ticker(ticker)
  df = tick.history(start=start_date, end=end_date)
  
  df['Adj Close'] = deepcopy(df['Close'])
  df = df.rename(columns = {
    'Open': 'AdjOpen',
    'High': 'AdjHigh',
    'Low': 'AdjLow',
    'Close': 'AdjClose',
    'Volume': 'AdjVolume',
    'Adj Close': 'Adj Close'
    })
  df = df.reset_index()
  df['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')
  
  df = df[['Date', 'AdjOpen', 'AdjHigh', 'AdjLow', 'AdjClose', 'Adj Close', 'AdjVolume']]
  #Date	      AdjLow	           AdjOpen	    AdjVolume	 AdjHigh	            AdjClose	         Adjusted Close
  #19-11-2019	66.34750366210940	66.9749984741211	76167200	67.0	            66.57250213623050	   65.41852569580080
  #20-11-2019	65.0999984741211	66.38500213623050	106234400	66.5199966430664	65.79750061035160	   64.65695190429690
  stock_df[ticker] = df
  #   print(stock_df.loc[stock_df['Date'] == '22-03-2019'])
  return df


def add_TALib_indicator(df, attribute, indicator_func, *args):
    '''
    Adds a column to a dataframe:
        column name is the name of the technical indicator as specified by indicator_func
        column content is the function calculated on the attribute column
    Example: add_TALib_indicator(df, 'AdjClose', ta.RSI, 14) creates a new column called RSI with 
             the 14 day RSI of the values of the column 'AdjClose'
    Inputs:
        df - dataframe - needs to be sorted in date ascending order
        attribute - column name to be used in TA-Lib calculation
        indicator_func - name of a TA-Lib function
        *args - optional parameters for indicator_func
        
    Oupputs:
        df - datarame with new column added
        func_name - name of the new colunm
    
    '''
    # get the name of the indicator from TA-Lib
    func_name = attribute + indicator_func.__name__ + str(*args)
    
    # add new column, calculated based on attribute column
    df.loc[:, func_name] = indicator_func(df.loc[:, attribute].values, *args)
    
    return df, func_name

def add_comparison_cols_for_indicator(df, base_col_name, indicator_col_name, delete_indicator_col=True):
    '''
    adds columns that compare indicator_col to base_col: ratio, crossover, above/below
    Inputs:
        df - dataframe
        base_col_name - name of column that the indicator will get compared to
        indicator_col_name - name of column that has indicator values
        delete_base_col - yes/no on if to keep the base col or not
    Output:
        df - modified df with added & removed columns
    '''
   
    # indicator to base column ratio:
    df.loc[:, indicator_col_name + '_to_' + base_col_name + '_ratio'] = df.loc[:, indicator_col_name] / df.loc[:, base_col_name]
    
    # base col above indicator:
    base_above_indicator_col_name = base_col_name + '_above_' + indicator_col_name
    df.loc[:, base_above_indicator_col_name] = df.loc[:, indicator_col_name] < df.loc[:, base_col_name]
    
    # did base cross indicator
    base_crossed_indicator_col_name = base_col_name + '_crossed_' + indicator_col_name
    df.loc[:, base_crossed_indicator_col_name] = df.loc[:, base_above_indicator_col_name] != df.loc[:, base_above_indicator_col_name].shift(1)
    
    if delete_indicator_col:
        df = df.drop(columns=indicator_col_name)
    
    return df

def feat_eng_changes_values_to_change(df, cols_set_vals_to_change, delete_original_cols=True):
    '''
    Instead of the actual values in some columns, we care about the change from one day to the next.
    This function calculates that change for the given columns and then either keeps or drops (default) the origianl columns
    Input:
        df - a dataframe
        cols_set_vals_to_change - names of columns to work on.
        delete_original_cols - keep or delete original columns
    Output:
        df - dataframe with new columns added. the value in row N is now the change from row N-1 to row N (instead of the actual values)
    '''    

    # calculate the change from row N-1 to row N
    df_chg_cols = (df[cols_set_vals_to_change] / df[cols_set_vals_to_change].shift(1) - 1)

    # add suffix to the column names
    df_chg_cols = df_chg_cols.add_suffix('_chg')

    # join the data onto the original data fram
    df = df.join(df_chg_cols)

    if delete_original_cols:
        # drop the original columns
        df = df.drop(columns=cols_set_vals_to_change)
        
    return df

'''
cols_set_vals_to_change = ['AdjVolume', 'AdjOpen', 'AdjLow', 'AdjHigh', 'AdjClose', 'AdjCloseSMA10', 'AdjCloseSMA50', 'AdjCloseSMA200']
df_X_base_data = feat_eng_changes_values_to_change(df_X_base_data, cols_set_vals_to_change, delete_original_cols=False)

df_X_base_data.tail().T
'''

n_days_features = 10
def create_feature_cols_df(df_X_base_data,
                           n_days_features=n_days_features,
                           cols_to_normalize_to_1_for_day_0 = ['AdjVolume', 'AdjOpen', 'AdjLow', 'AdjHigh', 'AdjClose']):
    '''
    Take dataframe with date index (sorted increasing time) with multiple columns and return a new wider dataframe
    where the rows for the last n_days_features have been pivoted into additional columns
    Input:
        df_X_base_data - dataframe with date index
        n_days_features - number of prior days that are pivoted into the rows
        cols_to_normalize_to_1_for_day_0 - columns that will be normalized for day N. eg prices, volumes
    Output:
        df_X - datafram that has length of df_X_base_data.shape[0] - n_days_features and more columns than df_X_base_data
    '''
    
    df_X = pd.DataFrame()
    
    # total lenght of df
    n_data_points = df_X_base_data.shape[0]
    
    # cycle through each row of df, start at n_days_features-1 because we wouldn't have enough history for first rows
    for i in range(n_days_features, n_data_points+1):
        # i contains the rows number of df

        df_extract = df_X_base_data.iloc[i-n_days_features:i, :]

        # pull out n_days_features of rows from current position
        df_extract = df_X_base_data.iloc[i-n_days_features:i, :].copy()

        # change the index to be "days into the past" - eg current day is 0, prior day is -1, ...
        df_extract.loc[:, 'row_index'] = range(-n_days_features+1, 1)

        # make this the new index
        df_extract.set_index('row_index', inplace=True)
        
        # normalize columns from dollars to "1" - turns the columns into ratios compared to day N (index 0)
        df_extract.loc[:, cols_to_normalize_to_1_for_day_0] = df_extract.loc[:, cols_to_normalize_to_1_for_day_0] / df_extract.loc[0, cols_to_normalize_to_1_for_day_0]

        # unstack and make it tall (ie unpivot)
        df_extract = df_extract.unstack().reset_index()

        # create new column with combined field names of attribute and index
        # eg: AdjClose_-1 for the adjusted close of day N-1 or AdjHigh_-4 for the adjusted High of day N-4
        df_extract['Attribute-index'] = df_extract['level_0'] + '_' + df_extract['row_index'].apply(str)
        # then drop Attributes and row_index columns since they are not needed anymore
        df_extract.drop(columns=['level_0', 'row_index'], inplace=True)

        # set index one and transpose
        target_row = df_extract.set_index('Attribute-index').T
        # we now have one row of data that represents the prior n_feature_days worth of data

        # fill in the target_row index with the date from the index of the source dataframe df_X_base_data (ie, day N)
        target_row['Index'] = df_X_base_data.index[i-1] # zero-indexed so need minus 1
        target_row = target_row.set_index('Index')

        df_X = df_X.append(target_row)
        
    return df_X

def feat_eng_append_date_index_content(df):
    '''
    Assumes that the df index is date-time. Bolts on additional columns about the date
    '''

    df['year'] = df.index.year.values
    df['month'] = df.index.month.values
    df['week'] = df.index.week.values
    df['weekday'] = df.index.weekday.values
    df['day'] = df.index.day.values
    df['year'] = df.index.year.values
    df['year'] = df.index.year.values
    
    return df

def get_feature_df(ticker, n_days_features):
    '''
    Full workflow: download ticker data from Quandl, define profitability flad, add several technical indicators as features,
    reshape the data, add some more features, return as dataFrame. The output is a df that has history for n_days_features encoded in one row
    Inputs:
        ticker - a single stock ticker name - must be a valid Quandl ticker string. eg 'GPRO.US'
        start_date - start date in format yyyy-mm-dd
        end_date - end date for daily stock price series in format yyyy-mm-dd
        n_days_features - positive integer that indicates how many days of history to fold into one date row
    Outputs:
        df_Xy - completed dataframe
        df_downloaded - the raw downloaded data for the same dates as in df_Xy
    '''
    global feature_df
    if os.environ.get('ENV') == 'Simulation':
        if feature_df.get(ticker, None) is not None:
            return feature_df[ticker]
    # download the stock data
    rowData = main_config.ROW_DATA

    #csv looks like this 
    
    #Date	      AdjLow	           AdjOpen	    AdjVolume	 AdjHigh	            AdjClose	         Adjusted Close
    #19-11-2019	66.34750366210940	66.9749984741211	76167200	67.0	            66.57250213623050	   65.41852569580080
    #20-11-2019	65.0999984741211	66.38500213623050	106234400	66.5199966430664	65.79750061035160	   64.65695190429690

    #Adjusted close is not used anywhere 

    df = fetch_stock_data(ticker)
    df['Date'] = pd.to_datetime(df.Date, format='%d-%m-%Y')
    #df['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')
    df = df.set_index('Date')
    df = df.iloc[rowData:]

    df_downloaded = df
    
    df_X_base_data = df
    
    # RSI
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.RSI, 14)
    # add threshold columns for above 80 and below 20
    df_X_base_data.loc[:, 'RSI_above_80'] = df_X_base_data.loc[:, indicator_name] > 80
    df_X_base_data.loc[:, 'RSI_below_20'] = df_X_base_data.loc[:, indicator_name] < 20
    # normalize to values between 0 and 1
    df_X_base_data.loc[:, indicator_name] = df_X_base_data.loc[:, indicator_name] / 100

    # SMA - Simple Moving Average - 10 day window
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.SMA, 10)
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjClose', indicator_name, delete_indicator_col=False)

    # SMA - Simple Moving Average - 50 day window
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.SMA, 50)
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjClose', indicator_name, delete_indicator_col=False)

    # SMA - Simple Moving Average - 200 day window
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.SMA, 200)
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjClose', indicator_name, delete_indicator_col=False)

    # more complex combinations:
    # Crossover between 50 day SMA and 200 day SMA
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjCloseSMA200', 'AdjCloseSMA50', delete_indicator_col=False)

    # Crossover between 10 day SMA and 50 day SMA
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjCloseSMA50', 'AdjCloseSMA10', delete_indicator_col=False)



    # feature engineering: instead of dollars/absolute values, calculate change from one day to next
    cols_set_vals_to_change = ['AdjVolume', 'AdjOpen', 'AdjLow', 'AdjHigh', 'AdjClose', 'AdjCloseSMA10', 'AdjCloseSMA50', 'AdjCloseSMA200']
    df_X_base_data = feat_eng_changes_values_to_change(df_X_base_data, cols_set_vals_to_change, delete_original_cols=False)

    # print(df_X_base_data.shape)
    # create wide features matrix that includes prior days' data as columns
    df_X = create_feature_cols_df(df_X_base_data,
                                  n_days_features= n_days_features,
                                  cols_to_normalize_to_1_for_day_0 = ['AdjVolume', 'AdjOpen', 'AdjLow', 'AdjHigh', 'AdjClose', 'AdjCloseSMA10', 'AdjCloseSMA50', 'AdjCloseSMA200'])


    
    # save stock ticker
    df_X['ticker'] = ticker 
    # change type of ticker column to categorical
    df_X['ticker'] = df_X['ticker'].astype('category')


    # remove all rows that have any NaNs in them - they come from undefined technical indicators or the reshaping and we just don't have 
    # any good strategy for imputation other than starting with more time series data
    df_X = df_X.loc[df_X.notnull().all(axis=1), :]
    

    #return df_Xy, df_downloaded_stock_data
    df_X = df_X.drop('ticker', axis=1)
    df_X.insert(len(df_X.columns), ticker, 1)
    df_X = df_X._convert(numeric=True)
    feature_df[ticker] = df_X
    df_X = df_X.round(6)
    return df_X


def get_feature_df_RL(ticker, n_days_features, start_date, end_date):
    '''
    Full workflow: download ticker data from Quandl, define profitability flad, add several technical indicators as features,
    reshape the data, add some more features, return as dataFrame. The output is a df that has history for n_days_features encoded in one row
    Inputs:
        ticker - a single stock ticker name - must be a valid Quandl ticker string. eg 'GPRO.US'
        start_date - start date in format yyyy-mm-dd
        end_date - end date for daily stock price series in format yyyy-mm-dd
        n_days_features - positive integer that indicates how many days of history to fold into one date row
    Outputs:
        df_Xy - completed dataframe
        df_downloaded - the raw downloaded data for the same dates as in df_Xy
    '''
    global feature_df
    if os.environ.get('ENV') == 'Simulation':
        if feature_df.get(ticker, None) is not None:
            return feature_df[ticker]
    # download the stock data
    rowData = main_config.ROW_DATA

    #csv looks like this 
    
    #Date	      AdjLow	           AdjOpen	    AdjVolume	 AdjHigh	            AdjClose	         Adjusted Close
    #19-11-2019	66.34750366210940	66.9749984741211	76167200	67.0	            66.57250213623050	   65.41852569580080
    #20-11-2019	65.0999984741211	66.38500213623050	106234400	66.5199966430664	65.79750061035160	   64.65695190429690


    df = fetch_stock_data_RL(ticker, start_date, end_date)
    df['Date'] = pd.to_datetime(df.Date, format='%d-%m-%Y')
    #df['Date'] = pd.to_datetime(df.Date, format='%Y-%m-%d')
    df = df.set_index('Date')
    df = df.iloc[rowData:]

    df_downloaded = df
    
    df_X_base_data = df
    
    # RSI
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.RSI, 14)
    # add threshold columns for above 80 and below 20
    df_X_base_data.loc[:, 'RSI_above_80'] = df_X_base_data.loc[:, indicator_name] > 80
    df_X_base_data.loc[:, 'RSI_below_20'] = df_X_base_data.loc[:, indicator_name] < 20
    # normalize to values between 0 and 1
    df_X_base_data.loc[:, indicator_name] = df_X_base_data.loc[:, indicator_name] / 100

    # SMA - Simple Moving Average - 10 day window
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.SMA, 10)
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjClose', indicator_name, delete_indicator_col=False)

    # SMA - Simple Moving Average - 50 day window
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.SMA, 50)
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjClose', indicator_name, delete_indicator_col=False)

    # SMA - Simple Moving Average - 200 day window
    df_X_base_data, indicator_name = add_TALib_indicator(df_X_base_data, 'AdjClose', ta.SMA, 200)
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjClose', indicator_name, delete_indicator_col=False)

    # more complex combinations:
    # Crossover between 50 day SMA and 200 day SMA
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjCloseSMA200', 'AdjCloseSMA50', delete_indicator_col=False)

    # Crossover between 10 day SMA and 50 day SMA
    df_X_base_data = add_comparison_cols_for_indicator(df_X_base_data, 'AdjCloseSMA50', 'AdjCloseSMA10', delete_indicator_col=False)



    # feature engineering: instead of dollars/absolute values, calculate change from one day to next
    cols_set_vals_to_change = ['AdjVolume', 'AdjOpen', 'AdjLow', 'AdjHigh', 'AdjClose', 'AdjCloseSMA10', 'AdjCloseSMA50', 'AdjCloseSMA200']
    df_X_base_data = feat_eng_changes_values_to_change(df_X_base_data, cols_set_vals_to_change, delete_original_cols=False)

    # print(df_X_base_data.shape)
    # create wide features matrix that includes prior days' data as columns
    df_X = create_feature_cols_df(df_X_base_data,
                                  n_days_features= n_days_features,
                                  cols_to_normalize_to_1_for_day_0 = ['AdjVolume', 'AdjOpen', 'AdjLow', 'AdjHigh', 'AdjClose', 'AdjCloseSMA10', 'AdjCloseSMA50', 'AdjCloseSMA200'])

    
    # save stock ticker
    df_X['ticker'] = ticker 
    # change type of ticker column to categorical
    df_X['ticker'] = df_X['ticker'].astype('category')


    # remove all rows that have any NaNs in them - they come from undefined technical indicators or the reshaping and we just don't have 
    # any good strategy for imputation other than starting with more time series data
    df_X = df_X.loc[df_X.notnull().all(axis=1), :]
    
    df_X = df_X.drop('ticker', axis=1)
    df_X.insert(len(df_X.columns), ticker, 1)
    df_X = df_X._convert(numeric=True)
    feature_df[ticker] = df_X
    df_X = df_X.round(6)
    return df_X
